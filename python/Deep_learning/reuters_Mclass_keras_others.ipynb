{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters_Mclass_keras_others.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSYqtkQEchkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "32bfef19-2eb0-4d22-ecd2-b69db21e7108"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "num_words=10000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17WiXt8Ic_fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhtJsf1qdJJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX3wZOmGdOUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY6pOKC3dSRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(46,activation='softmax'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksJ88uPYdcAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cliJeX2bdjQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train= x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwf6F5cGdm-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "13b9761d-1ec5-4a11-9f15-a921e93c6218"
      },
      "source": [
        "history = model.fit(partial_x_train,partial_y_train, epochs=5, batch_size=128,validation_data=(x_val,y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/5\n",
            "7982/7982 [==============================] - 2s 269us/step - loss: 0.1117 - accuracy: 0.9573 - val_loss: 1.3233 - val_accuracy: 0.7910\n",
            "Epoch 2/5\n",
            "7982/7982 [==============================] - 2s 270us/step - loss: 0.1036 - accuracy: 0.9574 - val_loss: 1.4027 - val_accuracy: 0.7770\n",
            "Epoch 3/5\n",
            "7982/7982 [==============================] - 2s 271us/step - loss: 0.0952 - accuracy: 0.9589 - val_loss: 1.5048 - val_accuracy: 0.7760\n",
            "Epoch 4/5\n",
            "7982/7982 [==============================] - 2s 277us/step - loss: 0.0928 - accuracy: 0.9587 - val_loss: 1.5059 - val_accuracy: 0.7680\n",
            "Epoch 5/5\n",
            "7982/7982 [==============================] - 2s 275us/step - loss: 0.0891 - accuracy: 0.9577 - val_loss: 1.6042 - val_accuracy: 0.7800\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}